# Markov

## Definitions

`Markov Chain`

: $$P(X_T = x_T | X_{T-1}, ..., X_{0} = x_{T-1}, ..., x_{0})=P(X_T = x_T | X_{T-1} = x_{T-1})$$

Memory-less stochastic process. The knowledge of the previous state is all that is necessary to determine the current state

`Markov Random Field`
: Set of random variables satisfying the Markov property for random fields

- is known as Markov Network or Undirected Graphical Model
- differs from  Baysesian networks which are directed and acyclic

## Markov Chain Monte Carlo

- [A simple introduction to Markov Chain Monte–Carlo sampling](https://link.springer.com/content/pdf/10.3758/s13423-016-1015-8.pdf) where we generate the next sample iteratively using previous samples
- [wikipedia](https://fr.wikipedia.org/wiki/M%C3%A9thode_de_Monte-Carlo_par_cha%C3%AEnes_de_Markov)

**Monte–Carlo** is the practice of estimating the properties of a distribution by examining random samples from the distribution

The Markov chain property of MCMC is the idea that the random samples are generated by a special sequential process

Condition to work:

  1. target distribution symmetric
  2. values calculated during step 4/5 must be prop. to posterior likelihoods & ignore initial samples (because initial guess can be very wrong)

??? question "`Markov Chain`"
    $$P(X_T = x_T | X_{T-1}, ..., X_{0} = x_{T-1}, ..., x_{0})=P(X_T = x_T | X_{T-1} = x_{T-1})$$
    Memory-less stochastic process: the knowledge of the previous state is all that is necessary to determine the current state

??? question "`Markov Random Field`"
    Set of random variables satisfying the Markov property for random fields

??? question "`Monte Carlo sampling`"
    Process of estimating the properties of a distribution by examining random samples from the distribution
